{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T02:05:30.436285Z",
     "start_time": "2020-01-23T02:05:30.431299Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy  import expand_dims\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "np.random.seed(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:15:42.105813Z",
     "start_time": "2020-01-23T00:15:42.102841Z"
    }
   },
   "source": [
    "## dog cat augmentatation\n",
    "\n",
    "- https://keraskorea.github.io/posts/2018-10-24-little_data_powerful_model/\n",
    "- https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "- 학습 데이터로 1,000장의 고양이 사진과 1,000장의 강아지 사진을 사용 (kaggle  25,000자)\n",
    "- 검증 데이터로는 각각 400장 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:18:58.794968Z",
     "start_time": "2020-01-23T00:18:58.766024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "img = load_img('cat.jpg') \n",
    "x = img_to_array(img)\n",
    "print(x.shape)   # w,h,c 인직 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:19:01.741164Z",
     "start_time": "2020-01-23T00:19:01.366065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# 검증 및 테스트 이미지는 augmentation을 적용하지 않음(이미지 원본을 사용)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 이미지를 배치 단위로 불러와 줄 generator입니다.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'smallcatdog/train', \n",
    "        target_size=(150, 150), \n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary') \n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:23:28.646613Z",
     "start_time": "2020-01-23T00:23:28.549119Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:57:03.056647Z",
     "start_time": "2020-01-23T00:55:31.959863Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 18s 148ms/step - loss: 0.4975 - accuracy: 0.7585 - val_loss: 0.6287 - val_accuracy: 0.6550\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 19s 151ms/step - loss: 0.4457 - accuracy: 0.7965 - val_loss: 0.5527 - val_accuracy: 0.7063\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.4104 - accuracy: 0.8170 - val_loss: 0.4459 - val_accuracy: 0.6950\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.3788 - accuracy: 0.8350 - val_loss: 0.4530 - val_accuracy: 0.7487\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.3402 - accuracy: 0.8540 - val_loss: 0.2877 - val_accuracy: 0.7350\n"
     ]
    }
   ],
   "source": [
    "# steps_per_epoch는 한 세대마다 몇 번 생성기로부터 데이터를 얻을지를 나타내는 값\n",
    "# 한 세대마다 사용되는 학습데이터의 수는 steps_per_epoch * batch_size\n",
    "        \n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,    # 2000/16     한번에 125개씩 생성\n",
    "        epochs=5,  #50\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)     # 800/16   한번에 50개씩 생성\n",
    "\n",
    "\n",
    "model.save(\"smallcatdog.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:29:43.502034Z",
     "start_time": "2020-01-23T00:29:41.443937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "0.6549999713897705\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator( test_generator, steps = 800/16)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:35:56.089617Z",
     "start_time": "2020-01-23T00:34:22.793234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.6995 - accuracy: 0.5440 - val_loss: 0.6903 - val_accuracy: 0.5638\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.6643 - accuracy: 0.6295 - val_loss: 0.6458 - val_accuracy: 0.6500\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.6146 - accuracy: 0.6805 - val_loss: 0.6308 - val_accuracy: 0.6538\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.5605 - accuracy: 0.7225 - val_loss: 0.5400 - val_accuracy: 0.6612\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.5207 - accuracy: 0.7430 - val_loss: 0.5244 - val_accuracy: 0.7013\n",
      "0.7012500166893005\n"
     ]
    }
   ],
   "source": [
    "# augmentation 없이  학습\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255 )\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 이미지를 배치 단위로 불러와 줄 generator입니다.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'smallcatdog/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # 모든 이미지의 크기가 150x150로 조정됩니다.\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # binary_crossentropy 손실 함수를 사용하므로 binary 형태로 라벨을 불러와야 합니다.\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=5, # 50\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "\n",
    "model.save(\"smallcatdog_wa.h5\")\n",
    "scores = model.evaluate_generator( test_generator,       steps = 800//16)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T01:34:51.916859Z",
     "start_time": "2020-01-23T01:34:51.445611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model2 = load_model('smallcatdog.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T01:34:59.363500Z",
     "start_time": "2020-01-23T01:34:59.356528Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T01:39:10.980492Z",
     "start_time": "2020-01-23T01:39:08.724547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n",
      "0.7350000143051147\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "scores = model2.evaluate_generator( test_generator, steps = 800//16)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T02:05:56.231224Z",
     "start_time": "2020-01-23T02:05:56.227338Z"
    }
   },
   "source": [
    "## 토마토 호박 수박"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T03:38:37.194912Z",
     "start_time": "2020-01-23T03:38:36.962512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# 검증 및 테스트 이미지는 augmentation을 적용하지 않음(이미지 원본을 사용)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 이미지를 배치 단위로 불러와 줄 generator입니다.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'clean-dataset/train', \n",
    "        target_size=(150, 150), \n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical') \n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'clean-dataset/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T03:38:37.396330Z",
     "start_time": "2020-01-23T03:38:37.294127Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T03:40:10.028515Z",
     "start_time": "2020-01-23T03:38:38.166436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.6850 - accuracy: 0.7033 - val_loss: 0.6382 - val_accuracy: 0.8400\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.4216 - accuracy: 0.8274 - val_loss: 1.0843 - val_accuracy: 0.8667\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.3623 - accuracy: 0.8623 - val_loss: 0.3185 - val_accuracy: 0.8800\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.3368 - accuracy: 0.8760 - val_loss: 0.3342 - val_accuracy: 0.8400\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.2894 - accuracy: 0.8877 - val_loss: 1.0358 - val_accuracy: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c2d49cf188>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# steps_per_epoch는 한 세대마다 몇 번 생성기로부터 데이터를 얻을지를 나타내는 값\n",
    "# 한 세대마다 사용되는 학습데이터의 수는 steps_per_epoch * batch_size\n",
    "        \n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,    # 2000/16     한번에 125개씩 생성\n",
    "        epochs=5,  #50\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=800 // batch_size)     # 800/16   한번에 50개씩 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T03:40:11.990811Z",
     "start_time": "2020-01-23T03:40:10.049499Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "0.8799999952316284\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator( test_generator, steps = 800/16)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imagenet에서 검색해서 다운하기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import requests\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04194289\") #ship synset  wnetid\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "str_soup=str(soup)\n",
    "split_urls=str_soup.split('\\r\\n')\n",
    "print(len(split_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02834778\")#bicycle synset\n",
    "bikes_soup = BeautifulSoup(bikes_page.content, 'html.parser')\n",
    "bikes_str_soup=str(bikes_soup)\n",
    "bikes_split_urls=bikes_str_soup.split('\\r\\n')\n",
    "print(len(bikes_split_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_downalod(urls, path, prefix) :    \n",
    "    idx = 0\n",
    "    for url in urls :\n",
    "        try:\n",
    "            resp = urllib.request.urlopen(url)\n",
    "            image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "            image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "            if ( len(image.shape)) == 3 :\n",
    "                print(url)\n",
    "                idx += 1\n",
    "                save_path = path + '/' + prefix + str(idx)+'.jpg'\n",
    "                cv2.imwrite(save_path,image)\n",
    "        except :\n",
    "            None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_downalod(split_urls, 'imagenet/aa', 'ship') # aa 폴더에 ship1 부터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_downalod(bikes_split_urls, 'imagenet/bikes', 'bike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen  = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "    \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'imagenet/train/',\n",
    "        target_size=(32, 32),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'imagenet/validation/',\n",
    "        target_size=(32, 32),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 =  Sequential()\n",
    "model2.add(Conv2D(4, kernel_size=(3, 3), activation='relu', input_shape=(32,32,3))) \n",
    "model2.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(16, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model2.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100, # 2000\n",
    "        epochs=2, validation_data=validation_generator   #65\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'imagenet/ship.jpg'\n",
    "img = load_img(img_path, target_size=(32, 32))\n",
    "x = img_to_array(img)\n",
    "print(x.shape)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "print(x.shape)\n",
    "preds = model2.predict(x)\n",
    "\n",
    "print(preds)\n",
    "print('Probability that the image is a Bicycle:', preds[0,0])\n",
    "print('Probability that the image is a Ship:', preds[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
